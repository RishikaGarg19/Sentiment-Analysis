{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-10-07T02:56:43.712632Z","iopub.execute_input":"2022-10-07T02:56:43.713022Z","iopub.status.idle":"2022-10-07T02:56:43.726950Z","shell.execute_reply.started":"2022-10-07T02:56:43.712974Z","shell.execute_reply":"2022-10-07T02:56:43.725963Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/sentiment140/training.1600000.processed.noemoticon.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"dataset = pd.read_csv('../input/sentiment140/training.1600000.processed.noemoticon.csv', encoding='latin1', header=None)\ndataset.head()","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","execution":{"iopub.status.busy":"2022-10-07T02:56:43.729127Z","iopub.execute_input":"2022-10-07T02:56:43.729525Z","iopub.status.idle":"2022-10-07T02:56:51.596302Z","shell.execute_reply.started":"2022-10-07T02:56:43.729483Z","shell.execute_reply":"2022-10-07T02:56:51.595164Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"   0           1                             2         3                4  \\\n0  0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY  _TheSpecialOne_   \n1  0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY    scotthamilton   \n2  0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY         mattycus   \n3  0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY          ElleCTF   \n4  0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY           Karoli   \n\n                                                   5  \n0  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n1  is upset that he can't update his Facebook by ...  \n2  @Kenichan I dived many times for the ball. Man...  \n3    my whole body feels itchy and like its on fire   \n4  @nationwideclass no, it's not behaving at all....  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1467810369</td>\n      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>_TheSpecialOne_</td>\n      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>1467810672</td>\n      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>scotthamilton</td>\n      <td>is upset that he can't update his Facebook by ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>1467810917</td>\n      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>mattycus</td>\n      <td>@Kenichan I dived many times for the ball. Man...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>1467811184</td>\n      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>ElleCTF</td>\n      <td>my whole body feels itchy and like its on fire</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>1467811193</td>\n      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>Karoli</td>\n      <td>@nationwideclass no, it's not behaving at all....</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"dataset.isna().sum()\nprint (dataset.values[0:1])\ndataset[0].unique()","metadata":{"execution":{"iopub.status.busy":"2022-10-07T02:56:51.597762Z","iopub.execute_input":"2022-10-07T02:56:51.598163Z","iopub.status.idle":"2022-10-07T02:56:52.440448Z","shell.execute_reply.started":"2022-10-07T02:56:51.598129Z","shell.execute_reply":"2022-10-07T02:56:52.439466Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"[[0 1467810369 'Mon Apr 06 22:19:45 PDT 2009' 'NO_QUERY'\n  '_TheSpecialOne_'\n  \"@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D\"]]\n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"array([0, 4])"},"metadata":{}}]},{"cell_type":"code","source":"x = dataset[5]\ny = dataset[0].values","metadata":{"execution":{"iopub.status.busy":"2022-10-07T02:56:52.443316Z","iopub.execute_input":"2022-10-07T02:56:52.443742Z","iopub.status.idle":"2022-10-07T02:56:52.449505Z","shell.execute_reply.started":"2022-10-07T02:56:52.443698Z","shell.execute_reply":"2022-10-07T02:56:52.448410Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import re\n\nhashtags = re.compile(r\"^#\\S+|\\s#\\S+\")\nmentions = re.compile(r\"^@\\S+|\\s@\\S+\")\nurls = re.compile(r\"https?://\\S+\")\n\ndef process_text(text):\n  text = hashtags.sub('hashtag', text)\n  text = mentions.sub('entity', text)\n  return text.strip().lower()\n  \ndef match_expr(pattern, string):\n  return not pattern.search(string) == None\n\ndef get_data_wo_urls(dataset):\n    link_with_urls = dataset.text.apply(lambda x: match_expr(urls, x))\n    return dataset[[not e for e in link_with_urls]]\n\nx=x.apply(process_text)","metadata":{"execution":{"iopub.status.busy":"2022-10-07T02:56:52.452518Z","iopub.execute_input":"2022-10-07T02:56:52.452984Z","iopub.status.idle":"2022-10-07T02:57:03.114711Z","shell.execute_reply.started":"2022-10-07T02:56:52.452935Z","shell.execute_reply":"2022-10-07T02:57:03.113837Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"print (x[0])","metadata":{"execution":{"iopub.status.busy":"2022-10-07T02:57:03.115870Z","iopub.execute_input":"2022-10-07T02:57:03.116184Z","iopub.status.idle":"2022-10-07T02:57:03.121410Z","shell.execute_reply.started":"2022-10-07T02:57:03.116147Z","shell.execute_reply":"2022-10-07T02:57:03.120574Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"entity http://twitpic.com/2y1zl - awww, that's a bummer.  you shoulda got david carr of third day to do it. ;d\n","output_type":"stream"}]},{"cell_type":"code","source":"def remove_urls (vTEXT):\n    vTEXT = re.sub(r'(https|http)?:\\/\\/(\\w|\\.|\\/|\\?|\\=|\\&|\\%)*\\b', '', vTEXT, flags=re.MULTILINE)\n    return(vTEXT)\n\nx=x.apply(remove_urls)\nprint (x[0])","metadata":{"execution":{"iopub.status.busy":"2022-10-07T02:57:03.122894Z","iopub.execute_input":"2022-10-07T02:57:03.123262Z","iopub.status.idle":"2022-10-07T02:57:13.503369Z","shell.execute_reply.started":"2022-10-07T02:57:03.123228Z","shell.execute_reply":"2022-10-07T02:57:13.502519Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"entity  - awww, that's a bummer.  you shoulda got david carr of third day to do it. ;d\n","output_type":"stream"}]},{"cell_type":"code","source":"from gensim.parsing.preprocessing import remove_stopwords, strip_numeric, strip_punctuation, strip_short, stem_text\nx=x.apply(remove_stopwords)\nx=x.apply(strip_numeric)\nx=x.apply(strip_punctuation)\nx=x.apply(strip_short)\nx=x.apply(stem_text)","metadata":{"execution":{"iopub.status.busy":"2022-10-07T02:57:13.504603Z","iopub.execute_input":"2022-10-07T02:57:13.504897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(x.values[0:5])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x, y, stratify=y, random_state=0, test_size=0.25)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(x_train[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.preprocessing.text import Tokenizer\nfrom keras.optimizers import Adam\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.layers import Dense, Input, SimpleRNN, Embedding, Dropout, Activation, GRU, Flatten\nfrom keras.layers import Bidirectional, GlobalMaxPool1D\nfrom keras.models import Model, Sequential\nfrom keras.layers import Convolution1D\nfrom keras import initializers, regularizers, constraints, optimizers, layers\n\nmax_features = 6000\ntokenizer = Tokenizer(num_words=max_features)\ntokenizer.fit_on_texts(x_train)\n\nlist_tokenized_train = tokenizer.texts_to_sequences(x_train)\nx_test = tokenizer.texts_to_sequences(x_test)\n\nmaxlen = 130\nx_train = pad_sequences(list_tokenized_train, maxlen=maxlen)\nx_test = pad_sequences(x_test, maxlen=maxlen)\n\nembed_size = 32\nmodel = Sequential()\nmodel.add(Embedding(max_features, embed_size))\nmodel.add((SimpleRNN(32, return_sequences=False)))\nmodel.add(Dense(20, activation=\"relu\"))\nmodel.add(Dropout(0.05))\nmodel.add(Dense(1, activation=\"sigmoid\"))\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n\nbatch_size = 64\nepochs = 5\nhist=model.fit(x_train,y_train, batch_size=batch_size, epochs=epochs, validation_data=(x_test, y_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}